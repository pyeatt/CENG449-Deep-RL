# -*- coding: utf-8 -*-
"""
Author: Colton Snyder

Class: CSC-449
Assignment: Programming Assignment 1
Due Date: September 19, 2022
"""

import numpy as np
from enum import IntEnum

class Action(IntEnum):
    UP = 0
    RIGHT = 1
    DOWN = 2
    LEFT = 3


# Policy evaluation threshold
THRESH = 0.05

# Reward gamma
GAMMA = 1

# Map from initial state and action -> next state and reward
stateActionRewardMap = [
    [(0, -1), (1, -1), (4, -1), (0, -1)],
    [(1, -1), (2, -1), (5, -1), (0, -1)],
    [(2, -1), (3, -1), (6, -1), (1, -1)],
    [(3, -1), (3, -1), (7, -1), (2, -1)],
    [(0, -1), (5, -1), (8, -1), (4, -1)],
    [(1, -1), (6, -1), (9, -1), (4, -1)],
    [(2, -1), (7, -1), (10, -1), (5, -1)],
    [(3, -1), (7, -1), (11, -1), (6, -1)],
    [(4, -1), (9, -1), (12, -1), (15, -2)],
    [(5, -1), (10, -1), (13, -1), (8, -1)],
    [(6, -1), (11, -1), (14, -1), (9, -1)],
    [(7, -1), (11, -1), (15, -1), (10, -1)],
    [(8, -1), (13, -1), (12, -1), (12, -1)],
    [(9, -1), (14, -1), (13, -1), (12, -1)],
    [(10, -1), (15, -1), (14, -1), (13, -1)],
    [(11, -1), (15, 0), (15, 0), (14, -1)],
    ]


# Initialize policy to randomly selecting one of the four directions at each step
policy = np.array([[0.25] * 4]*16);


# Initialize the value of each state to 0
stateValue = np.zeros(16)


def evaluatePolicy():
    global stateValue
    stateValue = np.zeros(16)
    difference = 99999
    
    while (difference > THRESH):
        tempStateValue = np.zeros(16)
        for i in range(15):
            for act in Action:
                actionProbability = policy[i][act]
                nextState, reward = stateActionRewardMap[i][act]
                nextStateValue = stateValue[nextState]
                tempStateValue[i] += actionProbability * (reward + GAMMA * nextStateValue)                
        difference = sum(abs(tempStateValue - stateValue))
        stateValue = tempStateValue
        if DEBUGGING:
            print(stateValue)
        
        
def improvePolicy():
    for i in range(16):
        maxActionValue = -99999999
        for act in Action:
            nextState, reward = stateActionRewardMap[i][act]
            nextStateValue = stateValue[nextState]
            actionValue = reward + nextStateValue
            
            if (actionValue > maxActionValue):
                maxActionValue = actionValue
                policy[i] = [1 if j == act else 0 for j in Action]
                
                
def printPolicy():
    print("-" * 17 )
    for i in range(4):
        for j in range(4):
            print("|", end=" ")
            statePolicy = policy[i*4 + j]
            
            if statePolicy[0] == 1:
                print("^", end=" ")
            elif statePolicy[1] == 1:
                print(">", end=" ")
            elif statePolicy[2] == 1:
                print("V", end=" ")
            else:
                print("<", end=" ")
        print("|")
        print("-" * 17)
        
def printValue():
    print("-" * 25)
    for i in range(4):
        for j in range(4):
            print("|", end="")
            print(f"{stateValue[i*4 + j]:5}", end="")
        print("|")
        print("-" * 25)
        
DEBUGGING = False

if __name__ == "__main__":
    policyChange = True
    while policyChange:
        if DEBUGGING:
            print("-------------Evaluating-------------")
        evaluatePolicy()
        
        oldPolicy = policy.copy()
        
        if DEBUGGING:
            print("-------------Improving--------------")
        improvePolicy()
        if DEBUGGING:
            print(policy)
        
        policyChange = not ((oldPolicy == policy).all())
    
    print("DONE!")
    print("-----------------------------------------")
    print("Optimal Deterministic Policy:")
    printPolicy()
    print(f"\n\nState Value Function for Above Policy (with {GAMMA=})")
    printValue()